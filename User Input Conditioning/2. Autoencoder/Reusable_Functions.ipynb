{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAYNF7vBhSn_"
   },
   "source": [
    "# Enhance reproducability of results\n",
    "\n",
    "Since all ML algorithms are inherently stochastic, running them multiple times give different solutions. However, for debugging and model performance comparison, it is important to have a degree of reproducability in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1upYArThSoB"
   },
   "outputs": [],
   "source": [
    "#%env PYTHONHASHSEED=0 \n",
    "#%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0tl7H8mhSoE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMC5oJHdhSoG"
   },
   "outputs": [],
   "source": [
    "def resetRNG(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRsEAzAgXadp"
   },
   "outputs": [],
   "source": [
    "#from keras.layers import Input, Dense, Flatten, Reshape, concatenate, Conv2D, Conv1D\n",
    "#from keras.layers import SeparableConv1D, Lambda, Conv2DTranspose, LeakyReLU\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K \n",
    "#from keras import initializers\n",
    "import keras\n",
    "\n",
    "from IPython.display import SVG, display\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import DATABASE\n",
    "\n",
    "Import the .npz Database containing 5SS mechanisms and cplr paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_DB_offline():\n",
    "    current_dir=os.getcwd()\n",
    "    db_path=os.path.join(current_dir,'..','1. DB Preprocessing','norm_database5SS.npz')\n",
    "    db = np.load(db_path)\n",
    "    cplr=db['cplrData']\n",
    "    mech=db['mechData']\n",
    "    \n",
    "    return cplr, mech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_DB_colab():\n",
    "    from google.colab import drive\n",
    "    \n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/My\\ Drive/Colab\\ Notebooks\n",
    "    db = np.load('norm_database5SS.npz')\n",
    "    cplr=db['cplrData']\n",
    "    mech=db['mechData']\n",
    "    \n",
    "    return cplr, mech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "youBC1SdXado"
   },
   "source": [
    "# Autoencoder TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6715LJKrXads"
   },
   "outputs": [],
   "source": [
    "# Train same model architecture multiple times since the training process is stochastic\n",
    "\n",
    "def AE_analysis(AE_model, iterations, x_train, x_test, filename='model'):\n",
    "    # AE_model: Keras Autoencoder model\n",
    "    # iterations: Times the autoencoder is trained from scratch. Only best model saved.\n",
    "    \n",
    "    val_loss_list=[]\n",
    "    best_val_loss=np.inf;\n",
    "    for i in range(iterations):\n",
    "        print('Model no. '+str(i+1))\n",
    "        AE, E = AE_model()\n",
    "        val_loss, train_data=train_AE(AE, E, x_train, x_test)\n",
    "        val_loss_list.append(val_loss)\n",
    "        if best_val_loss>val_loss:\n",
    "            best_AE=AE\n",
    "            best_E=E\n",
    "            best_train_data=train_data\n",
    "            best_val_loss=val_loss\n",
    "    \n",
    "    # PRINT MEAN, VARIANCE and BEST MODEL METRICS\n",
    "    print('**************************************************')\n",
    "    print('Validation Loss Stastics:')\n",
    "    print('Values: '+str(val_loss_list))\n",
    "    print('Mean: '+str(np.around(np.mean(val_loss_list), decimals=4)))\n",
    "    print('Standard Deviation: '+str(np.around(np.std(val_loss_list), decimals=4)))\n",
    "    print('**************************************************')\n",
    "    \n",
    "    # SAVE BEST MODEL\n",
    "    AEfilename='AE_'+filename+'_val_loss_'+str(best_val_loss)+'.h5'\n",
    "    AEfilepath=os.path.join('models',AEfilename)\n",
    "    best_AE.save(AEfilepath)\n",
    "    \n",
    "    return best_AE, best_E, best_train_data\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def train_AE(autoencoder, encoder, x_train, x_test, epochs=1000):\n",
    "    # TRAINING PHASE\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_absolute_error', \n",
    "                        metrics=['accuracy', 'mse', rmse])\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',\n",
    "                                  restore_best_weights=True)\n",
    "    autoencoder_train=autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=128, \n",
    "                                      shuffle=False, validation_data=(x_test, x_test), \n",
    "                                      verbose=0, callbacks=[earlyStopping])\n",
    "    \n",
    "    # TRAINING HISTORY\n",
    "    val_loss = autoencoder_train.history['val_loss']\n",
    "    f_val_loss=np.round_(val_loss[-1],decimals=4)\n",
    "    \n",
    "    return f_val_loss, autoencoder_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llgXoExKXad4"
   },
   "source": [
    "# Autoencoder VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6tp53--FXad6"
   },
   "outputs": [],
   "source": [
    "def visualize_AE(AE, train_data, x_test):\n",
    "    # VISUALIZING MODEL ARCHITECTURE\n",
    "    AE.summary()\n",
    "    display(SVG(model_to_dot(AE, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg')))\n",
    "    \n",
    "    # VISUALIZING TRAINING CURVES\n",
    "    visualize_train_curves(train_data)\n",
    "    \n",
    "    # VISUALIZE RECONSTRUCTED CURVES\n",
    "    reconst_curve = AE.predict(x_test)\n",
    "    visualize_reconstructed_CplrCurves(x_test, reconst_curve, 10)\n",
    "\n",
    "    \n",
    "def visualize_train_curves(train_data):\n",
    "    loss = train_data.history['loss']\n",
    "    val_loss = train_data.history['val_loss']\n",
    "    \n",
    "    f_loss=np.round_(loss[-1],decimals=4)\n",
    "    f_val_loss=np.round_(val_loss[-1],decimals=4)\n",
    "    \n",
    "    print('Training loss: '+str(f_loss))\n",
    "    print('Validation loss: '+str(f_val_loss))\n",
    "    \n",
    "    epochsRange = range(len(loss))\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(epochsRange, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochsRange, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def visualize_reconstructed_CplrCurves(x_test, reconst_curve, n=10, b_spline=False):\n",
    "    fig= plt.figure(figsize=(3*4, 3*n))\n",
    "    fig.suptitle('Isometric (3D), Top (X-Y Plane), Front (X-Z Plane) and Right (Y-Z Plane) View', fontsize=14, fontweight='bold')\n",
    "    for i in range(n):\n",
    "        # Isometric View\n",
    "        ax = plt.subplot(n, 4, 4*i+1, projection='3d')\n",
    "        if b_spline:\n",
    "            reconst_curve[i]=b_spline_interpolation(reconst_curve[i], 100)\n",
    "        plotPath3D(reconst_curve[i], ax, 1,'r' )\n",
    "        plotPath3D(x_test[i], ax, 1)\n",
    "        \n",
    "        #x-y, x-z, y-z plane view\n",
    "        xy_recon=reconst_curve[i,:,0:2]\n",
    "        xy_orig=x_test[i,:,0:2]\n",
    "        xz_recon=np.concatenate(([reconst_curve[i,:,0]], [reconst_curve[i,:,2]]),axis=0).T\n",
    "        xz_orig=np.concatenate(([x_test[i,:,0]], [x_test[i,:,2]]),axis=0).T\n",
    "        yz_recon=reconst_curve[i,:,1:3]\n",
    "        yz_orig=x_test[i,:,1:3]\n",
    "        \n",
    "        # Top View\n",
    "        ax = plt.subplot(n, 4, 4*i+2)\n",
    "        plotPath(xy_recon, ax, 1,'r' )\n",
    "        plotPath(xy_orig, ax, 1)\n",
    "        \n",
    "        # Front View\n",
    "        ax = plt.subplot(n, 4, 4*i+3)\n",
    "        plotPath(xz_recon, ax, 1,'r' )\n",
    "        plotPath(xz_orig, ax, 1)\n",
    "        \n",
    "        # Right View\n",
    "        ax = plt.subplot(n, 4, 4*i+4)\n",
    "        plotPath(yz_recon, ax, 1,'r' )\n",
    "        plotPath(yz_orig, ax, 1)\n",
    "        \n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDJng6vtXaeB"
   },
   "outputs": [],
   "source": [
    "# Plotting Functions\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "def plotPath3D(Pts, ax, limit, color = 'gray'):\n",
    "    xline=Pts[:,0]\n",
    "    yline=Pts[:,1]\n",
    "    zline=Pts[:,2]\n",
    "    ax.plot3D(xline, yline, zline, color)\n",
    "    ax.auto_scale_xyz([0, limit], [0, limit], [0, limit])\n",
    "    \n",
    "def plotPath(Pts, ax, limit, color = 'gray'):\n",
    "    xline=Pts[:,0]\n",
    "    yline=Pts[:,1]\n",
    "    ax.plot(xline, yline, color)\n",
    "    ax.set(xlim=(0, limit), ylim=(0, limit))\n",
    "\n",
    "def plotXYZ(center, RotMat, ax):\n",
    "    C=np.vstack((center,center,center))\n",
    "    R=RotMat\n",
    "    r=(1,0,0)\n",
    "    g=(0,1,0)\n",
    "    b=(0,0,1)\n",
    "    ax.quiver(C[:,0], C[:,1], C[:,2], R[:,0], R[:,1], R[:,2],color=(r,g,b,r,r,g,g,b,b))\n",
    "\n",
    "\n",
    "def b_spline_interpolation(inp_pts, out_n):\n",
    "    # Fit cubic B-spline to the points\n",
    "    xp=inp_pts[i,:,0]\n",
    "    yp=inp_pts[i,:,1]\n",
    "    zp=inp_pts[i,:,2]\n",
    "        \n",
    "    # Check for duplicate points as interpolation routine errors out\n",
    "    okay = np.where(np.abs(np.diff(xp)) + np.abs(np.diff(yp)) + np.abs(np.diff(zp)) > 0)\n",
    "    xp = np.r_[xp[okay], xp[-1]]\n",
    "    yp = np.r_[yp[okay], yp[-1]]\n",
    "    zp = np.r_[zp[okay], zp[-1]]\n",
    "    \n",
    "    tck, u =interpolate.splprep([xp,yp,zp],s=1)\n",
    "    num_pts=out_n\n",
    "    u_fine = np.linspace(0,1,num_pts)\n",
    "    x_f, y_f, z_f = interpolate.splev(u_fine, tck)\n",
    "    Path_f = np.vstack(([x_100],[y_100],[z_100])).T\n",
    "    \n",
    "    return Path_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize variation of coupler curves with change in z-space parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Architectures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Sigmoid Z_30 hidden_2 [300,100,100,30,100,100,300]\n",
    "def aeSig():\n",
    "    inp_curve=Input(shape=(100,3,))\n",
    "\n",
    "    # Encoding\n",
    "    x=Flatten()(inp_curve)\n",
    "    x=Dense(100, activation='sigmoid')(x)\n",
    "    x=Dense(100, activation='sigmoid')(x)\n",
    "    encoded=Dense(30, activation='sigmoid')(x)\n",
    "\n",
    "    # Decoding\n",
    "    x=Dense(100, activation='sigmoid')(encoded)\n",
    "    x=Dense(100, activation='sigmoid')(x)\n",
    "    x=Dense(300)(x)\n",
    "    decoded=Reshape((100, 3))(x)\n",
    "\n",
    "    autoencoder = Model(inp_curve, decoded)\n",
    "    encoder = Model(inp_curve, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "######################################################################\n",
    "# RELU Z_30 hidden_2 [300,100,100,30,100,100,300]\n",
    "def aeRELU():\n",
    "    inp_curve=Input(shape=(100,3,))\n",
    "\n",
    "    # Encoding\n",
    "    x=Flatten()(inp_curve)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    encoded=Dense(30, activation='relu')(x)\n",
    "\n",
    "    # Decoding\n",
    "    x=Dense(100, activation='relu')(encoded)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    x=Dense(300)(x)\n",
    "    decoded=Reshape((100, 3))(x)\n",
    "\n",
    "    autoencoder = Model(inp_curve, decoded)\n",
    "    encoder = Model(inp_curve, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "######################################################################\n",
    "# LRELU Z_30 hidden_2 [300,100,100,30,100,100,300]\n",
    "def aeLRELU():\n",
    "    inp_curve=Input(shape=(100,3,))\n",
    "\n",
    "    # Encoding\n",
    "    x=Flatten()(inp_curve)\n",
    "    x=Dense(100)(x)\n",
    "    x=LeakyReLU(alpha=0.01)(x)\n",
    "    x=Dense(100)(x)\n",
    "    x=LeakyReLU(alpha=0.01)(x)\n",
    "    x=Dense(30)(x)\n",
    "    encoded=LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "    # Decoding\n",
    "    x=Dense(100)(encoded)\n",
    "    x=LeakyReLU(alpha=0.01)(x)\n",
    "    x=Dense(100)(x)\n",
    "    x=LeakyReLU(alpha=0.01)(x)\n",
    "    x=Dense(300)(x)\n",
    "    decoded=Reshape((100, 3))(x)\n",
    "\n",
    "    autoencoder = Model(inp_curve, decoded)\n",
    "    encoder = Model(inp_curve, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "######################################################################\n",
    "# Z_2 hidden_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
