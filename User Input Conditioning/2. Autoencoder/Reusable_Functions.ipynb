{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"Reusable_Functions.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cAYNF7vBhSn_"},"source":["# Enhance reproducability of results\n","\n","Since all ML algorithms are inherently stochastic, running them multiple times give different solutions. However, for debugging and model performance comparison, it is important to have a degree of reproducability in the results."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T1upYArThSoB","colab":{}},"source":["#%env PYTHONHASHSEED=0 \n","#%env CUDA_VISIBLE_DEVICES=\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g0tl7H8mhSoE","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import random\n","import os\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","np.random.seed(1)\n","random.seed(1)\n","tf.set_random_seed(1)\n","\n","config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n","from keras import backend as K\n","sess = tf.Session(graph=tf.get_default_graph(), config=config)\n","K.set_session(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VMC5oJHdhSoG","colab":{}},"source":["def resetRNG(seed_value):\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    tf.set_random_seed(seed_value)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZadLIHRDWBDz","colab_type":"text"},"source":["# Module IMPORTS"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uRsEAzAgXadp","colab":{}},"source":["#from keras.layers import Input, Dense, Flatten, Reshape, concatenate, Conv2D, Conv1D\n","#from keras.layers import SeparableConv1D, Lambda, Conv2DTranspose, LeakyReLU\n","from keras.layers import *\n","from keras.models import Model, load_model\n","from keras import regularizers\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras import backend as K \n","#from keras import initializers\n","import keras\n","\n","from IPython.display import SVG, display\n","from keras.utils.vis_utils import plot_model, model_to_dot"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5dYlRKHEWBD4","colab_type":"text"},"source":["# Import DATABASE\n","\n","Import the .npz Database containing 5SS mechanisms and cplr paths."]},{"cell_type":"code","metadata":{"id":"TWjm5q3TWBD5","colab_type":"code","colab":{}},"source":["def import_DB():\n","    current_dir=os.getcwd()\n","    db_path=os.path.join(current_dir,'..','1. DB Preprocessing','norm_database5SS.npz')\n","    db = np.load(db_path)\n","    cplr=db['cplrData']\n","    mech=db['mechData']\n","    \n","    return cplr, mech"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"youBC1SdXado"},"source":["# Autoencoder TRAINING"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6715LJKrXads","colab":{}},"source":["# Train same model architecture multiple times since the training process is stochastic\n","\n","def AE_analysis(AE_model, iterations, x_train, x_test, filename='model'):\n","    # AE_model: Keras Autoencoder model\n","    # iterations: Times the autoencoder is trained from scratch. Only best model saved.\n","    \n","    val_loss_list=[]\n","    best_val_loss=np.inf;\n","    for i in range(iterations):\n","        print('Model no. '+str(i+1))\n","        AE, E = AE_model()\n","        val_loss, train_data=train_AE(AE, E, x_train, x_test)\n","        val_loss_list.append(val_loss)\n","        if best_val_loss>val_loss:\n","            best_AE=AE\n","            best_E=E\n","            best_train_data=train_data\n","            best_val_loss=val_loss\n","    \n","    # PRINT MEAN, VARIANCE and BEST MODEL METRICS\n","    print('**************************************************')\n","    print('Validation Loss Stastics:')\n","    print('Values: '+str(val_loss_list))\n","    print('Mean: '+str(np.around(np.mean(val_loss_list), decimals=4)))\n","    print('Standard Deviation: '+str(np.around(np.std(val_loss_list), decimals=4)))\n","    print('**************************************************')\n","    \n","    # SAVE BEST MODEL\n","    AEfilename='AE_'+filename+'_val_loss_'+str(best_val_loss)+'.h5'\n","    AEfilepath=os.path.join('models',AEfilename)\n","    best_AE.save(AEfilepath)\n","    \n","    return best_AE, best_E, best_train_data\n","\n","def rmse(y_true, y_pred):\n","        #return K.sqrt(K.mean(K.square(y_pred - y_true))) \n","        return K.sqrt(keras.losses.mean_squared_error(y_true, y_pred))\n","\n","def train_AE(autoencoder, encoder, x_train, x_test, epochs=1000):\n","    # TRAINING PHASE\n","    # Losses: mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","    autoencoder.compile(optimizer='adam', loss=rmse, \n","                        metrics=['accuracy', 'mse', 'mae', rmse])\n","    earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min',\n","                                  restore_best_weights=True)\n","    autoencoder_train=autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=128, \n","                                      shuffle=False, validation_data=(x_test, x_test), \n","                                      verbose=0, callbacks=[earlyStopping])\n","    \n","    # TRAINING HISTORY\n","    val_loss = autoencoder_train.history['val_loss']\n","    f_val_loss=np.round_(val_loss[-1],decimals=4)\n","    \n","    return f_val_loss, autoencoder_train"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"llgXoExKXad4"},"source":["# Autoencoder VISUALIZATION"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6tp53--FXad6","colab":{}},"source":["def visualize_AE(AE, train_data, x_test):\n","    # VISUALIZING MODEL ARCHITECTURE\n","    AE.summary()\n","    #display(SVG(model_to_dot(AE, show_shapes=True, show_layer_names=False, dpi=65).create(prog='dot', format='svg')))\n","    \n","    # VISUALIZING TRAINING CURVES\n","    visualize_train_curves(train_data)\n","    \n","    # VISUALIZE RECONSTRUCTED CURVES\n","    reconst_curve = AE.predict(x_test)\n","    visualize_reconstructed_CplrCurves(x_test, reconst_curve, 10)\n","\n","    \n","def visualize_train_curves(train_data):\n","    loss = train_data.history['loss']\n","    val_loss = train_data.history['val_loss']\n","    \n","    f_loss=np.round_(loss[-1],decimals=4)\n","    f_val_loss=np.round_(val_loss[-1],decimals=4)\n","    \n","    print('Training loss: '+str(f_loss))\n","    print('Validation loss: '+str(f_val_loss))\n","    \n","    epochsRange = range(len(loss))\n","    plt.figure(figsize=(14, 7))\n","    plt.plot(epochsRange, loss, 'r', label='Training loss')\n","    plt.plot(epochsRange, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.legend()\n","    plt.show()\n","\n","    \n","def visualize_reconstructed_CplrCurves(x_test, reconst_curve, n=10, b_spline=False):\n","    fig= plt.figure(figsize=(3*4, 3*n))\n","    fig.suptitle('Isometric (3D), Top (X-Y Plane), Front (X-Z Plane) and Right (Y-Z Plane) View', fontsize=14, fontweight='bold')\n","    for i in range(n):\n","        # Isometric View\n","        ax = plt.subplot(n, 4, 4*i+1, projection='3d')\n","        if b_spline:\n","            reconst_curve[i]=b_spline_interpolation(reconst_curve[i], 100)\n","        plotPath3D(reconst_curve[i], ax, 1,'r' )\n","        plotPath3D(x_test[i], ax, 1)\n","        \n","        #x-y, x-z, y-z plane view\n","        xy_recon=reconst_curve[i,:,0:2]\n","        xy_orig=x_test[i,:,0:2]\n","        xz_recon=np.concatenate(([reconst_curve[i,:,0]], [reconst_curve[i,:,2]]),axis=0).T\n","        xz_orig=np.concatenate(([x_test[i,:,0]], [x_test[i,:,2]]),axis=0).T\n","        yz_recon=reconst_curve[i,:,1:3]\n","        yz_orig=x_test[i,:,1:3]\n","        \n","        # Top View\n","        ax = plt.subplot(n, 4, 4*i+2)\n","        plotPath(xy_recon, ax, 1,'r' )\n","        plotPath(xy_orig, ax, 1)\n","        \n","        # Front View\n","        ax = plt.subplot(n, 4, 4*i+3)\n","        plotPath(xz_recon, ax, 1,'r' )\n","        plotPath(xz_orig, ax, 1)\n","        \n","        # Right View\n","        ax = plt.subplot(n, 4, 4*i+4)\n","        plotPath(yz_recon, ax, 1,'r' )\n","        plotPath(yz_orig, ax, 1)\n","        \n","    fig.tight_layout(rect=[0, 0, 1, 0.97])\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pDJng6vtXaeB","colab":{}},"source":["# Plotting Functions\n","\n","%matplotlib inline\n","#%matplotlib notebook\n","from mpl_toolkits import mplot3d\n","import matplotlib.pyplot as plt\n","from scipy import interpolate\n","\n","\n","def plotPath3D(Pts, ax, limit, color = 'gray'):\n","    xline=Pts[:,0]\n","    yline=Pts[:,1]\n","    zline=Pts[:,2]\n","    ax.plot3D(xline, yline, zline, color)\n","    ax.auto_scale_xyz([0, limit], [0, limit], [0, limit])\n","    \n","def plotPath(Pts, ax, limit, color = 'gray'):\n","    xline=Pts[:,0]\n","    yline=Pts[:,1]\n","    ax.plot(xline, yline, color)\n","    ax.set(xlim=(0, limit), ylim=(0, limit))\n","\n","def plotXYZ(center, RotMat, ax):\n","    C=np.vstack((center,center,center))\n","    R=RotMat\n","    r=(1,0,0)\n","    g=(0,1,0)\n","    b=(0,0,1)\n","    ax.quiver(C[:,0], C[:,1], C[:,2], R[:,0], R[:,1], R[:,2],color=(r,g,b,r,r,g,g,b,b))\n","\n","\n","def b_spline_interpolation(inp_pts, out_n):\n","    # Fit cubic B-spline to the points\n","    xp=inp_pts[i,:,0]\n","    yp=inp_pts[i,:,1]\n","    zp=inp_pts[i,:,2]\n","        \n","    # Check for duplicate points as interpolation routine errors out\n","    okay = np.where(np.abs(np.diff(xp)) + np.abs(np.diff(yp)) + np.abs(np.diff(zp)) > 0)\n","    xp = np.r_[xp[okay], xp[-1]]\n","    yp = np.r_[yp[okay], yp[-1]]\n","    zp = np.r_[zp[okay], zp[-1]]\n","    \n","    tck, u =interpolate.splprep([xp,yp,zp],s=1)\n","    num_pts=out_n\n","    u_fine = np.linspace(0,1,num_pts)\n","    x_f, y_f, z_f = interpolate.splev(u_fine, tck)\n","    Path_f = np.vstack(([x_100],[y_100],[z_100])).T\n","    \n","    return Path_f"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ChhqHY4WBEK","colab_type":"text"},"source":["## Visualize variation of coupler curves with change in z-space parameters"]},{"cell_type":"markdown","metadata":{"id":"wOu1qhiRWBEL","colab_type":"text"},"source":["# Autoencoder Architectures: "]},{"cell_type":"code","metadata":{"id":"QWaqUhhRWBEN","colab_type":"code","colab":{}},"source":["######################################################################\n","# Sigmoid Z_30 hidden_2 [300,100,100,30,100,100,300]\n","def aeSig():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(100, activation='sigmoid')(x)\n","    x=Dense(100, activation='sigmoid')(x)\n","    encoded=Dense(30, activation='sigmoid')(x)\n","\n","    # Decoding\n","    x=Dense(100, activation='sigmoid')(encoded)\n","    x=Dense(100, activation='sigmoid')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_30 hidden_2 [300,100,100,30,100,100,300]\n","def aeRELU():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    encoded=Dense(30, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(100, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# LRELU Z_30 hidden_2 [300,100,100,30,100,100,300]\n","def aeLRELU():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(100)(x)\n","    x=LeakyReLU(alpha=0.01)(x)\n","    x=Dense(100)(x)\n","    x=LeakyReLU(alpha=0.01)(x)\n","    x=Dense(30)(x)\n","    encoded=LeakyReLU(alpha=0.01)(x)\n","\n","    # Decoding\n","    x=Dense(100)(encoded)\n","    x=LeakyReLU(alpha=0.01)(x)\n","    x=Dense(100)(x)\n","    x=LeakyReLU(alpha=0.01)(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCgRBscnWBEP","colab_type":"code","colab":{}},"source":["######################################################################\n","# RELU Z_2 hidden_3 [300,150,100,70,2,70,100,150,300]\n","def aeZ2():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(2, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_3 hidden_3 [300,150,100,70,3,70,100,150,300]\n","def aeZ3():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(3, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_10 hidden_3 [300,150,100,70,10,70,100,150,300]\n","def aeZ10():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(10, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_15 hidden_3 [300,150,100,70,15,70,100,150,300]\n","def aeZ15():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(15, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_30 hidden_3 [300,150,100,70,30,70,100,150,300]\n","def aeZ30():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(30, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_60 hidden_3 [300,150,100,70,60,70,100,150,300]\n","def aeZ60():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(60, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# RELU Z_300 hidden_3 [300,150,100,70,300,70,100,150,300]\n","def aeZ300():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(300, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","    \n","######################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnrUe0R7Jcro","colab_type":"code","colab":{}},"source":["######################################################################\n","# Shallow RELU Z_30 hidden_1 [300,100,30,100,300]\n","def aeDepth1():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(100, activation='relu')(x)\n","    encoded=Dense(30, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(100, activation='relu')(encoded)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################\n","# Deep RELU Z_30 hidden_5 [300,200,150,100,75,50,30,50,75,100,150,200,300]\n","def aeDepth5():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(200, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(75, activation='relu')(x)\n","    x=Dense(50, activation='relu')(x)\n","    encoded=Dense(30, activation='relu')(x)\n","\n","    # Decoding\n","    x=Dense(50, activation='relu')(encoded)\n","    x=Dense(75, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(200, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7hmXgX3rJiH","colab_type":"code","colab":{}},"source":["######################################################################\n","# Regularized RELU Z_3 hidden_3 [300,150,100,70,3,70,100,150,300]\n","def aeReg():\n","    inp_curve=Input(shape=(100,3,))\n","\n","    # Encoding\n","    x=Flatten()(inp_curve)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(70, activation='relu')(x)\n","    encoded=Dense(3, activation='relu',activity_regularizer=regularizers.l1(10e-7))(x)\n","\n","    # Decoding\n","    x=Dense(70, activation='relu')(encoded)\n","    x=Dense(100, activation='relu')(x)\n","    x=Dense(150, activation='relu')(x)\n","    x=Dense(300)(x)\n","    decoded=Reshape((100, 3))(x)\n","\n","    autoencoder = Model(inp_curve, decoded)\n","    encoder = Model(inp_curve, encoded)\n","    \n","    return autoencoder, encoder\n","\n","######################################################################"],"execution_count":0,"outputs":[]}]}