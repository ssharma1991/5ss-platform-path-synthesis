{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Path Descriptors using Z space of Autoencoder\n",
    "\n",
    "Autoencoder are good at:\n",
    "- **dimensionality reduction** for data visualization\n",
    "- **data denoising** for robust feature learning\n",
    "\n",
    "Dimensions of Input space= n x 100 x 3\n",
    "Dimensions of Latent space (z-space)= z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance reproducability of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env PYTHONHASHSEED=0 \n",
    "#%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetRNG(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import .npz Database containing 5SS mechanisms and cplr paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data offline\n",
    "import os\n",
    "current_dir=os.getcwd()\n",
    "db_path=os.path.join(current_dir,'..','1. DB Preprocessing','norm_database5SS.npz')\n",
    "db = np.load(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data on Google CoLab\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#db = np.load('norm_database5SS.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cplrData', 'mechData']\n",
      "(1453, 100, 3)\n",
      "(1453, 11, 3)\n"
     ]
    }
   ],
   "source": [
    "print(db.files)\n",
    "cplr=db['cplrData']\n",
    "mech=db['mechData']\n",
    "\n",
    "print(cplr.shape)\n",
    "print(mech.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the database in Train/Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= cplr\n",
    "\n",
    "# Split data into training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, _, _ = train_test_split(x, x, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to TRAIN an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, SeparableConv1D, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train same model architecture multiple times since the training process is stochastic\n",
    "\n",
    "def AE_analysis(AE_model, iterations, x_train, x_test, filename='model'):\n",
    "    val_loss_list=[]\n",
    "    best_val_loss=np.inf;\n",
    "    for i in range(iterations):\n",
    "        print('Model no. '+str(i+1))\n",
    "        AE, E = AE_model()\n",
    "        val_loss, train_data=train_AE(AE, E, x_train, x_test)\n",
    "        val_loss_list.append(val_loss)\n",
    "        if best_val_loss>val_loss:\n",
    "            best_AE=AE\n",
    "            best_E=E\n",
    "            best_train_data=train_data\n",
    "            best_val_loss=val_loss\n",
    "    \n",
    "    # PRINT MEAN, VARIANCE and BEST MODEL METRICS\n",
    "    print(val_loss_list)\n",
    "    print('Average Validation Loss: '+str(np.mean(val_loss_list)))\n",
    "    \n",
    "    # SAVE BEST MODEL\n",
    "    AEfilename='AE_'+filename+'_val_loss_'+str(best_val_loss)+'.h5'\n",
    "    AEfilepath=os.path.join('models',AEfilename)\n",
    "    best_AE.save(AEfilepath)\n",
    "    \n",
    "    return best_AE, best_E, best_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AE(autoencoder, encoder, x_train, x_test, epochs=500):\n",
    "    # TRAINING PHASE\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min',\n",
    "                                  restore_best_weights=True)\n",
    "    autoencoder_train=autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=128, \n",
    "                                      shuffle=False, validation_data=(x_test, x_test), \n",
    "                                      verbose=0, callbacks=[earlyStopping])\n",
    "    \n",
    "    # TRAINING DATA\n",
    "    val_loss = autoencoder_train.history['val_loss']\n",
    "    f_val_loss=np.round_(val_loss[-1],decimals=4)\n",
    "    \n",
    "    return f_val_loss, autoencoder_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to VISUALIZE an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_AE(AE, train_data, x_test):\n",
    "    # VISUALIZING TRAINING CURVES\n",
    "    visualize_train_curves(train_data)\n",
    "    \n",
    "    # VISUALIZE RECONSTRUCTED CURVES\n",
    "    reconst_curve = AE.predict(x_test)\n",
    "    visualize_reconstructed_CplrCurves(x_test, reconst_curve, 20)\n",
    "\n",
    "    \n",
    "def visualize_train_curves(train_data):\n",
    "    loss = train_data.history['loss']\n",
    "    val_loss = train_data.history['val_loss']\n",
    "    \n",
    "    f_loss=np.round_(loss[-1],decimals=4)\n",
    "    f_val_loss=np.round_(val_loss[-1],decimals=4)\n",
    "    \n",
    "    print('Training loss: '+str(f_loss))\n",
    "    print('Validation loss: '+str(f_val_loss))\n",
    "    \n",
    "    epochsRange = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochsRange, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochsRange, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def visualize_reconstructed_CplrCurves(x_test, reconst_curve, n=10, b_spline=False):\n",
    "    plt.figure(figsize=(3*n, 3))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1, projection='3d')\n",
    "        if b_spline:\n",
    "            reconst_curve[i]=b_spline_interpolation(reconst_curve[i], 100)\n",
    "        plotPath(reconst_curve[i], ax, 2,'r' )\n",
    "        plotPath(x_test[i], ax, 2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Functions\n",
    "\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "def plotPath(Pts, ax, limit, color = 'gray'):\n",
    "    xline=Pts[:,0]\n",
    "    yline=Pts[:,1]\n",
    "    zline=Pts[:,2]\n",
    "    ax.plot3D(xline, yline, zline, color)\n",
    "    ax.auto_scale_xyz([-limit, limit], [-limit, limit], [-limit, limit])\n",
    "\n",
    "def plotXYZ(center, RotMat, ax):\n",
    "    C=np.vstack((center,center,center))\n",
    "    R=RotMat\n",
    "    r=(1,0,0)\n",
    "    g=(0,1,0)\n",
    "    b=(0,0,1)\n",
    "    ax.quiver(C[:,0], C[:,1], C[:,2], R[:,0], R[:,1], R[:,2],color=(r,g,b,r,r,g,g,b,b))\n",
    "\n",
    "\n",
    "def b_spline_interpolation(inp_pts, out_n):\n",
    "    # Fit cubic B-spline to the points\n",
    "    xp=inp_pts[i,:,0]\n",
    "    yp=inp_pts[i,:,1]\n",
    "    zp=inp_pts[i,:,2]\n",
    "        \n",
    "    # Check for duplicate points as interpolation routine errors out\n",
    "    okay = np.where(np.abs(np.diff(xp)) + np.abs(np.diff(yp)) + np.abs(np.diff(zp)) > 0)\n",
    "    xp = np.r_[xp[okay], xp[-1]]\n",
    "    yp = np.r_[yp[okay], yp[-1]]\n",
    "    zp = np.r_[zp[okay], zp[-1]]\n",
    "    \n",
    "    tck, u =interpolate.splprep([xp,yp,zp],s=1)\n",
    "    num_pts=out_n\n",
    "    u_fine = np.linspace(0,1,num_pts)\n",
    "    x_f, y_f, z_f = interpolate.splev(u_fine, tck)\n",
    "    Path_f = np.vstack(([x_100],[y_100],[z_100])).T\n",
    "    \n",
    "    return Path_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convolutional Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution (Normal) AutoEncoder Z=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution (Spatial Separable) AutoEncoder Z=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model no. 1\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00096: early stopping\n",
      "Model no. 2\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Add, MaxPooling1D, UpSampling1D\n",
    "\n",
    "def autoEncoderCov1DZ10():\n",
    "    inp_curve=Input(shape=(100,3,))\n",
    "\n",
    "    # Encoding\n",
    "    x1=SeparableConv1D(4,5,padding='same')(inp_curve)\n",
    "    x1=MaxPooling1D(2)(x1)\n",
    "    x1=Flatten()(x1)\n",
    "    x2=SeparableConv1D(4,20,padding='same')(inp_curve)\n",
    "    x2=MaxPooling1D(2)(x2)\n",
    "    x2=Flatten()(x2)\n",
    "    x3=SeparableConv1D(4,50,padding='same')(inp_curve)\n",
    "    x3=MaxPooling1D(2)(x3)\n",
    "    x3=Flatten()(x3)\n",
    "    x=concatenate([x1,x2,x3], axis=1)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    x=Dense(30, activation='relu')(x)\n",
    "    encoded=Dense(10, activation='relu')(x)\n",
    "\n",
    "    # Decoding\n",
    "    x=Dense(30, activation='relu')(encoded)\n",
    "    x=Dense(100, activation='relu')(x)\n",
    "    x=Dense(600, activation='relu')(x)\n",
    "    x1=Lambda(lambda x: x[:,0:50*4])(x)\n",
    "    x1=UpSampling1D(2)(x1)\n",
    "    x1=Reshape((100, 4))(x1)\n",
    "    x1=SeparableConv1D(4,5,padding='same')(x1)\n",
    "    x2=Lambda(lambda x: x[:,50*4:2*50*4])(x)\n",
    "    x2=UpSampling1D(2)(x2)\n",
    "    x2=Reshape((100, 4))(x2)\n",
    "    x2=SeparableConv1D(4,5,padding='same')(x2)\n",
    "    x3=Lambda(lambda x: x[:,2*50*4:3*50*4])(x)\n",
    "    x3=UpSampling1D(2)(x3)\n",
    "    x3=Reshape((100, 4))(x3)\n",
    "    x3=SeparableConv1D(4,5,padding='same')(x3)\n",
    "    x=Add()([x1, x2, x3])\n",
    "    decoded=SeparableConv1D(3,5,padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(inp_curve, decoded)\n",
    "    encoder = Model(inp_curve, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "AE,E,train_data =AE_analysis(autoEncoderCov1DZ10, 10, x_train, x_test, filename='Z10C1D')\n",
    "visualize_AE(AE, train_data, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution (with FFT) AutoEncoder Z=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder Z=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
