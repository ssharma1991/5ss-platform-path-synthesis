# Synthesis of Spatial Platform with five TS dyads

A TS dyad consists of a rigid binary link with a spherical joint and a universal joint at each end. Five such links can be combined to form a one degree-of-freedom spatial mechanism which can generate complex motions. An example of 5-TS platform can be seen below. It has been modelled using Autodesk Inventor.
<img src="Innocenti Example.JPG" width="900" title="5-TS Platform"/>

## Input Enhancement for Defect-free mechanism generation

### Motivation
Spatial mechanism like the 5-TS platforms have been a tough problem to solve for kinematic designers. State-of-art academic research has enabled designers to solve the motion synthesis which results in upto 15,504 mechanisms. However, while the branch defect is a minor inconvenience for planar cases, they end up being a deal-breaker in spatial case. A spatial mechanism coupler paths can have significantly more defects in its trajectory and checking each of 15k+ solutions is time-consuming. As a result, finding practical spatial mechanisms for path or motion synthesis has been elusive.

In this project, a generative deep learning framework has been created which learns family of defect-free paths generated by a 5-TS platform. We use this framework to enhance user inputs into task paths which are more probable to generate defect-free mechanisms. 

### Data Generation
We create 7500 random spatial 5-TS mechanisms and simulate them using a solver. The solver is implemented using MATLAB and uses Newton-Rhapson optimization to create defect-free paths. This database represents a family of paths a general 5-TS mechanism can achieve.

### Data Preprocessing
Before the generated data can be used for machine learning, the data needs to be normalized, cleaned and augmented. 
- A 7500 simulated coupler curves are represented using $n$ 3-D datapoints each where $n$ ranges from 2 to 3126. Curves made of less than 10 datapoints are ignored since they contain extremely less information. 
- First, we normalize the total number of points used to represent the remaining 7408 coupler curves. A fourth order b-spline interpolation curve is fitted to the these curves. Then, 100 datapoints are uniformly sampled on each curve leading to an arc-length parametrization.
- Next, the location, orentation and scale of these curves are normalized. The mean of curves is translated to origin. The principal axes of curve are rotated to align with x,y,z axes. The curves are scaled to unit arc-length.
- When the solver is simulating a 5ss-mechanism, it may jump from one branch to another due to inherent limitations of numerical methods. These invalid coupler paths have extremely high curvature/torsion at points where the branch jump happens. The z-score of Max Curvature, Max Torsion and Min Torsion values is used to filter these outliers. This results in a clean database containing 7200 coupler paths.
- The database in its present form is unbalanced i.e. it has more samples of coupler paths which are more probable while lesser samples of other more diverse examples. This leads to the algorithm not learning well since it comes across the more probable examples most of the time. To overcome this bias, a limited number of diverse paths are selected from the complete database by undersampling similar curves. A metric based on Curvature and Torsion properties is used to compare the similatity of two curves. This leads to a balanced DB containing 5021 coupler paths.
- According to the domain knowledge, we know that if a path is a valid coupler path, its mirrored curve is also a valid path. Thus, coupler paths mirrored across xy,yz and zx planes are added to encorage the model to be invariant to mirror operations.
- It is desirable for our algorithm to be able to handle missing input data. To enable this, we augment the data with paths missing random information and also create the mask representing the missing information.
- Finally, some noise is added to all the curves. This acts as a regularizer to ML algorithm, encourages robust learning and avoids overfitting.


### Deep Learning
Once a dataset having desired properties(being defect-free in this case) is available, it can be used to train a Machine Learning model. Since the model learns only from good data, it gets biased towards it and is able to learn the inherent properties. This biased model is then used on input data to generate data with desirable properties. Generally speaking, this desirable property of data could be anything like pivot location constraints, mechanism compactness, etc. However, we would need a new model for each property. 

Many different architectures are being tested to find the best for our use-case.
- Convolutional Autoencoders: In the field of kinematic synthesis, it is well known that use of Fourier Descriptors is extremely advantageous. This domain knowledge makes convolution AE much better suited for learning since a convolution operation can be defined as multiplication of Fourier Descriptors. Consequently, convolution operation can be used to isolate different frequency components.
- Variational Autoencoders: Its advantage is that it can generate multiple outputs for same input. This makes it suitable for mechanism design since designers are always interested in multiple solution mechanisms.
- Conditional Variational Autoencoders: These VAE include an additional feature input to both encoder and decoder network. This feature can enable interactive control of generated output. One such example is in image inpainting where the image mask acts as additional feature. Thus in our usecase, we can use C-VAE to complete partial paths inputted by user. [link](https://arxiv.org/abs/1806.02382)
- 1-Encoder n-Decoder architecture: This is an extremely new architecture being used in face-swapping applications. This model learns the underlying *shared details* in faces like expression and orientation of face. These latent features can then be used to generate a similar face of another person. In our use-case, this model could possibly be used to capture high-level user design intent and then map that intent to generate family of curves of different types of mechanism. Thus, this would essentially extend the existing framework to include type synthesis. [link](https://medium.com/@jonathan_hui/how-deep-learning-fakes-videos-deepfakes-and-how-to-detect-it-c0b50fbf7cb9), [Face2Face](https://ieeexplore.ieee.org/document/7780631), 


[Tips to improve ML performance](https://machinelearningmastery.com/machine-learning-performance-improvement-cheat-sheet/)



